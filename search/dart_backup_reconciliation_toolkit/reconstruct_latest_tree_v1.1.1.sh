#!/usr/bin/env bash
#
# reconstruct_latest_tree.sh
# Dart Backup Reconciliation Toolkit – Latest Tree Reconstructor v1.1.1
#
# Companion to:
#   find_latest_flutter_source.sh – Flutter Source Version Finder v1.9.2
#
# PURPOSE:
#   Reads CSV or JSON output generated by find_latest_flutter_source_v1.9.2.sh
#   and reconstructs a directory tree containing:
#
#   Default (A3):
#     - Newest: <group_key>.LATEST.dart
#     - Older:  <group_key>.OLD_1.dart, OLD_2, ...
#
#   With --latest-only:
#     - Only <group_key>.LATEST.dart is copied, older instances are skipped.
#
# FEATURES:
#   - Parallel copy of all scheduled instances
#   - Optional checksum verification (source in dry-run, destination otherwise)
#   - Optional HTML dashboard report (clean B2 style)
#   - Summary: groups, instances, copies, missing, bytes, time range, checksum stats
#   - Safe handling of missing files (logged, shown in HTML)
#
set -euo pipefail

VERSION="1.1.1"

########################################
# CLI helpers
########################################
if [[ -t 1 ]]; then
  BOLD=$'\e[1m'; YELLOW=$'\e[33m'; GREEN=$'\e[32m'; RED=$'\e[31m'; RESET=$'\e[0m'
else
  BOLD=""; YELLOW=""; GREEN=""; RED=""; RESET=""
fi

bold()   { printf '%b%s%b\n' "$BOLD" "$1" "$RESET"; }
yellow() { printf '%b%s%b\n' "$YELLOW" "$1" "$RESET"; }
green()  { printf '%b%s%b\n' "$GREEN" "$1" "$RESET"; }
red()    { printf '%b%s%b\n' "$RED" "$1" "$RESET"; }
log()    { printf "%s\n" "$*"; }
debug()  { [[ $DEBUG -eq 1 ]] && printf "[DEBUG] %s\n" "$*" >&2; }

########################################
# Defaults / globals
########################################
JSON_FILE=""
CSV_FILE=""
OUT_DIR=""
HTML_REPORT=""
LATEST_ONLY=0
VERIFY_CHECKSUMS=0
DRY_RUN=0
DEBUG=0

# Summary counters
TOTAL_GROUPS=0
TOTAL_INSTANCES=0
TOTAL_MISSING=0
TOTAL_COPIES=0
TOTAL_BYTES=0
OLDEST_EPOCH=""
NEWEST_EPOCH=""
LARGEST_SIZE=0
LARGEST_PATH=""

CHECK_OK=0
CHECK_BAD=0
CHECK_SKIPPED=0

START_EPOCH=$(date +%s)

########################################
# Usage
########################################
usage() {
cat <<EOF
$(bold "reconstruct_latest_tree.sh – Latest Tree Reconstructor v$VERSION")

Options:
  --json FILE          JSON export from find_latest_flutter_source_v1.9.2.sh
  --csv FILE           CSV export from find_latest_flutter_source_v1.9.2.sh
  --out DIR            Output directory for reconstructed tree (required)
  --html-report FILE   Generate HTML dashboard report
  --latest-only        Only copy newest instance per group (no OLD_n files)
  --verify-checksums   Verify SHA256 against analyzer output
  --dry-run            Show what would be copied, but do not modify filesystem
  --debug              Enable debug logging
  --version            Show version
  -h, --help           Show this help

Notes:
  - Exactly one of --json or --csv must be provided.
  - Relative paths inside OUT/ are determined by group_key.
  - For best lib/… layout, run analyzer with: --group-by relpath
EOF
}

########################################
# Parse arguments
########################################
if [[ $# -eq 0 ]]; then usage; exit 0; fi

while [[ $# -gt 0 ]]; do
  case "$1" in
    --json) JSON_FILE="$2"; shift 2 ;;
    --csv)  CSV_FILE="$2"; shift 2 ;;
    --out)  OUT_DIR="$2"; shift 2 ;;
    --html-report) HTML_REPORT="$2"; shift 2 ;;
    --latest-only) LATEST_ONLY=1; shift ;;
    --verify-checksums) VERIFY_CHECKSUMS=1; shift ;;
    --dry-run) DRY_RUN=1; shift ;;
    --debug) DEBUG=1; shift ;;
    --version) echo "reconstruct_latest_tree.sh version $VERSION"; exit 0 ;;
    -h|--help) usage; exit 0 ;;
    *) echo "Unknown option: $1" >&2; usage; exit 1 ;;
  esac
done

########################################
# Validate
########################################
if [[ -z "$OUT_DIR" ]]; then
  echo "Error: --out DIR is required." >&2
  exit 1
fi

if [[ -n "$JSON_FILE" && -n "$CSV_FILE" ]]; then
  echo "Error: Provide only one of --json or --csv, not both." >&2
  exit 1
fi

if [[ -z "$JSON_FILE" && -z "$CSV_FILE" ]]; then
  echo "Error: Must provide either --json or --csv." >&2
  exit 1
fi

if [[ -n "$JSON_FILE" && ! -f "$JSON_FILE" ]]; then
  echo "JSON file not found: $JSON_FILE" >&2
  exit 1
fi

if [[ -n "$CSV_FILE" && ! -f "$CSV_FILE" ]]; then
  echo "CSV file not found: $CSV_FILE" >&2
  exit 1
fi

if [[ -n "$JSON_FILE" ]]; then
  if ! command -v jq >/dev/null 2>&1; then
    echo "Error: jq is required to parse JSON." >&2
    exit 1
  fi
fi

mkdir -p "$OUT_DIR"

########################################
# Data structures
########################################
# ALL_FILES[key] = newline list "epoch,path,sha,size,mtime"
declare -A ALL_FILES

########################################
# Parsers
########################################
parse_csv() {
  local csv="$1"
  local header=1

  # Analyzer CSV header: group_key,path,mtime,size,sha256
  while IFS=',' read -r key path mtime size sha; do
    if [[ $header -eq 1 ]]; then
      header=0
      continue
    fi

    key="${key%\"}";   key="${key#\"}"
    path="${path%\"}"; path="${path#\"}"
    mtime="${mtime%\"}"; mtime="${mtime#\"}"
    size="${size%\"}"; size="${size#\"}"
    sha="${sha%\"}";   sha="${sha#\"}"

    [[ -z "$path" ]] && continue

    epoch=$(date -d "$mtime" +%s 2>/dev/null || echo 0)
    ALL_FILES["$key"]+="${epoch},${path},${sha},${size},${mtime}"$'\n'
  done < "$csv"
}

parse_json() {
  local json="$1"
  mapfile -t rows < <(jq -c '.[]' "$json")

  for row in "${rows[@]}"; do
    key=$(echo "$row"  | jq -r '.group_key')
    path=$(echo "$row" | jq -r '.path')
    mtime=$(echo "$row"| jq -r '.mtime')
    size=$(echo "$row" | jq -r '.size')
    sha=$(echo "$row"  | jq -r '.sha256')

    [[ -z "$path" ]] && continue

    epoch=$(date -d "$mtime" +%s 2>/dev/null || echo 0)
    ALL_FILES["$key"]+="${epoch},${path},${sha},${size},${mtime}"$'\n'
  done
}

[[ -n "$CSV_FILE" ]] && { debug "Parsing CSV: $CSV_FILE"; parse_csv "$CSV_FILE"; }
[[ -n "$JSON_FILE" ]] && { debug "Parsing JSON: $JSON_FILE"; parse_json "$JSON_FILE"; }

if [[ ${#ALL_FILES[@]} -eq 0 ]]; then
  echo "No file groups present in input. Nothing to reconstruct."
  exit 0
fi

########################################
# Helper: suffix before extension
########################################
add_suffix_to_relpath() {
  local rel="$1"
  local suffix="$2"
  local dir fname base ext

  dir="$(dirname "$rel")"
  fname="$(basename "$rel")"

  if [[ "$fname" == *.* ]]; then
    base="${fname%.*}"
    ext="${fname##*.}"
    echo "$dir/${base}${suffix}.${ext}"
  else
    echo "$dir/${fname}${suffix}"
  fi
}

########################################
# Build copy task list and stats
########################################
COPY_TASKS=()

for key in "${!ALL_FILES[@]}"; do
  ((TOTAL_GROUPS++))

  sorted=$(echo -e "${ALL_FILES[$key]}" | sed '/^$/d' | sort -t',' -k1,1nr)

  idx=0
  while IFS=',' read -r epoch path sha size mtime; do
    [[ -z "$epoch" ]] && continue

    ((TOTAL_INSTANCES++))

    # Time range
    if [[ -z "$OLDEST_EPOCH" || "$epoch" -lt "$OLDEST_EPOCH" ]]; then
      OLDEST_EPOCH="$epoch"
    fi
    if [[ -z "$NEWEST_EPOCH" || "$epoch" -gt "$NEWEST_EPOCH" ]]; then
      NEWEST_EPOCH="$epoch"
    fi

    # Largest file
    if [[ "$size" =~ ^[0-9]+$ ]] && (( size > LARGEST_SIZE )); then
      LARGEST_SIZE="$size"
      LARGEST_PATH="$path"
    fi

    # LATEST-ONLY: skip non-latest for copying, but still count as instance
    if (( LATEST_ONLY == 1 && idx > 0 )); then
      ((idx++))
      continue
    fi

    local suffix role
    if (( idx == 0 )); then
      role="LATEST"
      suffix=".LATEST"
    else
      role="OLD_$idx"
      suffix=".OLD_$idx"
    fi

    rel_with_suffix=$(add_suffix_to_relpath "$key" "$suffix")
    dest_path="$OUT_DIR/$rel_with_suffix"

    if [[ -f "$path" ]]; then
      ((TOTAL_COPIES++))
      TOTAL_BYTES=$((TOTAL_BYTES + size))
      COPY_TASKS+=("$path|$dest_path|$key|$role|$epoch|$size|$mtime|$sha")
    else
      ((TOTAL_MISSING++))
    fi

    ((idx++))
  done <<< "$sorted"
done

########################################
# Parallel copy
########################################
bold "Reconstructing latest tree (v$VERSION)"
log "Output directory   : $OUT_DIR"
log "Planned copies     : $TOTAL_COPIES"
log "Latest-only mode   : $LATEST_ONLY"
log "Dry-run            : $DRY_RUN"
log "Verify checksums   : $VERIFY_CHECKSUMS"
log ""

if [[ ${#COPY_TASKS[@]} -eq 0 ]]; then
  log "No copy tasks to execute."
else
  JOBS=$(( $(command -v nproc >/dev/null 2>&1 && nproc || echo 4) ))
  if (( DRY_RUN == 1 )); then
    yellow "DRY-RUN enabled: no files will be copied."
  else
    if xargs -P 2>/dev/null <<<"" >/dev/null 2>&1; then
      debug "Using parallel copy with xargs -P $JOBS"
      printf '%s\n' "${COPY_TASKS[@]}" \
        | xargs -P "$JOBS" -n 1 -I{} bash -c '
            IFS="|" read -r src dest group role epoch size mtime sha <<<"$1"
            mkdir -p "$(dirname "$dest")"
            cp "$src" "$dest"
          ' _ {}
    else
      log "xargs -P not available; falling back to serial copy."
      for line in "${COPY_TASKS[@]}"; do
        IFS="|" read -r src dest group role epoch size mtime sha <<<"$line"
        mkdir -p "$(dirname "$dest")"
        cp "$src" "$dest"
      done
    fi
  fi
fi

########################################
# Checksum verification
########################################
declare -A CHK_STATUS_DEST  # dest_path -> OK / MISMATCH / MISSING_DEST
declare -A CHK_STATUS_SRC   # src_path  -> OK / MISMATCH / MISSING_SRC

if (( VERIFY_CHECKSUMS == 1 )); then
  log ""
  log "$(bold "Verifying checksums…")"

  if (( DRY_RUN == 0 )); then
    # Verify destination files
    for line in "${COPY_TASKS[@]}"; do
      IFS="|" read -r src dest group role epoch size mtime sha <<<"$line"
      if [[ ! -f "$dest" ]]; then
        CHK_STATUS_DEST["$dest"]="MISSING_DEST"
        ((CHECK_SKIPPED++))
        continue
      fi
      actual=$(sha256sum "$dest" 2>/dev/null | awk '{print $1}')
      if [[ "$actual" == "$sha" ]]; then
        CHK_STATUS_DEST["$dest"]="OK"
        ((CHECK_OK++))
      else
        CHK_STATUS_DEST["$dest"]="MISMATCH"
        ((CHECK_BAD++))
      fi
    done
  else
    # DRY RUN: verify source (no dest files)
    for line in "${COPY_TASKS[@]}"; do
      IFS="|" read -r src dest group role epoch size mtime sha <<<"$line"
      if [[ ! -f "$src" ]]; then
        CHK_STATUS_SRC["$src"]="MISSING_SRC"
        ((CHECK_SKIPPED++))
        continue
      fi
      actual=$(sha256sum "$src" 2>/dev/null | awk '{print $1}')
      if [[ "$actual" == "$sha" ]]; then
        CHK_STATUS_SRC["$src"]="OK"
        ((CHECK_OK++))
      else
        CHK_STATUS_SRC["$src"]="MISMATCH"
        ((CHECK_BAD++))
      fi
    done
  fi

  log "Checksum OK       : $CHECK_OK"
  log "Checksum mismatch : $CHECK_BAD"
  log "Checksum skipped  : $CHECK_SKIPPED"
fi

########################################
# HTML report
########################################
write_html_report() {
  local html="$1"

  local oldest_str newest_str
  if [[ -n "$OLDEST_EPOCH" ]]; then
    oldest_str=$(date -d @"$OLDEST_EPOCH")
  else
    oldest_str="N/A"
  fi
  if [[ -n "$NEWEST_EPOCH" ]]; then
    newest_str=$(date -d @"$NEWEST_EPOCH")
  else
    newest_str="N/A"
  fi

  {
    cat <<HEAD
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Dart Backup Latest Tree Report</title>
<style>
  body { font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif; margin: 1.5rem; background: #f8fafc; color: #111827; }
  h1 { font-size: 1.8rem; margin-bottom: 0.5rem; }
  h2 { margin-top: 2rem; }
  .summary { background: #e5f3ff; padding: 1rem; border-radius: 8px; margin-bottom: 1rem; }
  .summary dt { font-weight: 600; float: left; clear: left; width: 220px; }
  .summary dd { margin: 0 0 0.3rem 230px; }
  table { border-collapse: collapse; width: 100%; font-size: 0.9rem; margin-top: 0.5rem; }
  th, td { border: 1px solid #d1d5db; padding: 4px 6px; text-align: left; vertical-align: top; }
  th { background: #e5e7eb; }
  tr.latest { background: #ecfdf5; }  /* green-ish */
  tr.missing { background: #fef3c7; } /* amber */
  tr.bad { background: #fee2e2; }     /* red-ish */
  code { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; }
</style>
</head>
<body>
<h1>Dart Backup Latest Tree Report</h1>
<p>Generated by <code>reconstruct_latest_tree.sh</code> v$VERSION</p>

<div class="summary">
  <h2>Summary</h2>
  <dl>
    <dt>Output directory</dt><dd><code>$OUT_DIR</code></dd>
    <dt>Total groups</dt><dd>$TOTAL_GROUPS</dd>
    <dt>Total file instances</dt><dd>$TOTAL_INSTANCES</dd>
    <dt>Total copies scheduled</dt><dd>$TOTAL_COPIES</dd>
    <dt>Missing source files</dt><dd>$TOTAL_MISSING</dd>
    <dt>Total data copied</dt><dd>$TOTAL_BYTES bytes</dd>
    <dt>Oldest mtime</dt><dd>$oldest_str</dd>
    <dt>Newest mtime</dt><dd>$newest_str</dd>
    <dt>Latest-only mode</dt><dd>$LATEST_ONLY</dd>
    <dt>Dry-run</dt><dd>$DRY_RUN</dd>
    <dt>Verify checksums</dt><dd>$VERIFY_CHECKSUMS</dd>
HEAD

    if (( LARGEST_SIZE > 0 )); then
      echo "    <dt>Largest file</dt><dd>$LARGEST_SIZE bytes – <code>${LARGEST_PATH}</code></dd>"
    fi

    if (( VERIFY_CHECKSUMS == 1 )); then
      echo "    <dt>Checksum OK</dt><dd>$CHECK_OK</dd>"
      echo "    <dt>Checksum mismatches</dt><dd>$CHECK_BAD</dd>"
      echo "    <dt>Checksum skipped</dt><dd>$CHECK_SKIPPED</dd>"
    fi

    cat <<MID
  </dl>
</div>

<h2>Per-file Details</h2>
<table>
  <thead>
    <tr>
      <th>Group Key</th>
      <th>Role</th>
      <th>Status</th>
      <th>MTime</th>
      <th>Size (bytes)</th>
      <th>SHA256</th>
      <th>Source Path</th>
      <th>Destination Path</th>
    </tr>
  </thead>
  <tbody>
MID

    # Build map of scheduled copies
    declare -A COPIED_MAP
    for line in "${COPY_TASKS[@]}"; do
      IFS="|" read -r src dest group role epoch size mtime sha <<<"$line"
      COPIED_MAP["$src|$dest"]="SCHEDULED"
    done

    for key in "${!ALL_FILES[@]}"; do
      sorted=$(echo -e "${ALL_FILES[$key]}" | sed '/^$/d' | sort -t',' -k1,1nr)
      idx=0
      while IFS=',' read -r epoch path sha size mtime; do
        [[ -z "$epoch" ]] && continue

        local role suffix
        if (( idx == 0 )); then
          role="LATEST"
          suffix=".LATEST"
        else
          role="OLD_$idx"
          suffix=".OLD_$idx"
        fi

        rel_with_suffix=$(add_suffix_to_relpath "$key" "$suffix")
        dest_path="$OUT_DIR/$rel_with_suffix"

        status=""
        row_class=""

        if [[ ! -f "$path" ]]; then
          status="MISSING SOURCE"
          row_class="missing"
        elif (( LATEST_ONLY == 1 && idx > 0 )); then
          status="SKIPPED (LATEST-ONLY)"
          row_class="missing"
        else
          # scheduled?
          if [[ -n "${COPIED_MAP["$path|$dest_path"]+x}" ]]; then
            if (( DRY_RUN == 1 )); then
              status="WOULD COPY"
            else
              status="COPIED"
            fi
          else
            status="SKIPPED"
          fi

          # checksum overlay
          if (( VERIFY_CHECKSUMS == 1 )); then
            local cs=""
            if (( DRY_RUN == 0 )); then
              cs="${CHK_STATUS_DEST["$dest_path"]-}"
              if [[ "$cs" == "OK" ]]; then
                status="$status (VERIFIED)"
              elif [[ "$cs" == "MISMATCH" ]]; then
                status="CHECKSUM MISMATCH"
                row_class="bad"
              elif [[ "$cs" == "MISSING_DEST" ]]; then
                status="DEST MISSING (VERIFY)"
                row_class="missing"
              fi
            else
              cs="${CHK_STATUS_SRC["$path"]-}"
              if [[ "$cs" == "OK" ]]; then
                status="$status (SRC VERIFIED)"
              elif [[ "$cs" == "MISMATCH" ]]; then
                status="CHECKSUM MISMATCH (SRC)"
                row_class="bad"
              elif [[ "$cs" == "MISSING_SRC" ]]; then
                status="MISSING SOURCE (VERIFY)"
                row_class="missing"
              fi
            fi
          fi

          # mark newest row green if not already colored
          if (( idx == 0 )) && [[ -z "$row_class" ]]; then
            row_class="latest"
          fi
        fi

        printf '  <tr class="%s">\n' "$row_class"
        printf '    <td><code>%s</code></td>\n' "$key"
        printf '    <td>%s</td>\n' "$role"
        printf '    <td>%s</td>\n' "$status"
        printf '    <td>%s</td>\n' "$mtime"
        printf '    <td>%s</td>\n' "$size"
        printf '    <td><code>%s</code></td>\n' "$sha"
        printf '    <td><code>%s</code></td>\n' "$path"
        printf '    <td><code>%s</code></td>\n' "$dest_path"
        printf "  </tr>\n"

        ((idx++))
      done
    done

    cat <<FOOT
  </tbody>
</table>

</body>
</html>
FOOT
  } > "$html"
}

if [[ -n "$HTML_REPORT" ]]; then
  log ""
  log "Writing HTML report to: $HTML_REPORT"
  write_html_report "$HTML_REPORT"
fi

########################################
# Summary
########################################
END_EPOCH=$(date +%s)
ELAPSED=$((END_EPOCH - START_EPOCH))

log ""
bold "Summary"
log "  Version          : $VERSION"
log "  Output directory : $OUT_DIR"
log "  Total groups     : $TOTAL_GROUPS"
log "  Total instances  : $TOTAL_INSTANCES"
log "  Copies scheduled : $TOTAL_COPIES"
log "  Missing sources  : $TOTAL_MISSING"
log "  Total bytes      : $TOTAL_BYTES"
if [[ -n "$OLDEST_EPOCH" ]]; then
  log "  Oldest mtime     : $(date -d @"$OLDEST_EPOCH")"
fi
if [[ -n "$NEWEST_EPOCH" ]]; then
  log "  Newest mtime     : $(date -d @"$NEWEST_EPOCH")"
fi
if (( LARGEST_SIZE > 0 )); then
  log "  Largest file     : $LARGEST_SIZE bytes – $LARGEST_PATH"
fi
if (( VERIFY_CHECKSUMS == 1 )); then
  log "  Checksum OK      : $CHECK_OK"
  log "  Checksum mismatch: $CHECK_BAD"
  log "  Checksum skipped : $CHECK_SKIPPED"
fi
log "  Elapsed time     : ${ELAPSED}s"
log ""
bold "Done."
